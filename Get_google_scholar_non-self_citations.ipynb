{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1dea4be-9d4d-4ea9-a787-d1dd3d5d8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a09f0b3b-bedb-4fec-a408-421ef9e995af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Excel sheet\n",
    "wb = openpyxl.load_workbook('articles.xlsx')\n",
    "ws = wb.active\n",
    "\n",
    "# extract all the article titles in column A and store them in a list\n",
    "article_titles = [cell.value for cell in ws['A']]\n",
    "# article_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e83f24e4-09e1-4b18-b15f-8a3028c5ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up webdriver\n",
    "\n",
    "# create ChromeOptions object to configure headless and incognito modes\n",
    "options = Options()\n",
    "# options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "# options.add_argument('--incognito')\n",
    "\n",
    "# create ChromeDriver object with headless and incognito modes enabled\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# wait for browser to launch\n",
    "time.sleep(2)\n",
    "\n",
    "# navigate to Google Scholar\n",
    "driver.get('https://scholar.google.com/schhp?hl=en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74267839-48cd-4bbd-b950-f248e9960302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centrifuge modelling of energy piles subjected to heating and cooling cycles in clay\n",
      "-author:CWW Ng -author:C Shi -author:A Gunawan -author:L Laloui\n",
      "39\n",
      "Effects of root geometry and transpiration on pull-out resistance\n",
      "-author:V Kamchoom -author:AK Leung -author:CWW Ng\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "for article_title in article_titles:\n",
    "    print(article_title)\n",
    "\n",
    "    # find search box and enter article title\n",
    "    search_box = driver.find_element(By.NAME, 'q')\n",
    "    search_box.clear()\n",
    "    search_box.send_keys(article_title)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "    # wait for search result page to load\n",
    "    time.sleep(5)\n",
    "    \n",
    "    ## GET AUTHOR NAMES FOR SELF CITATIONS\n",
    "\n",
    "    # get the HTML code of the search result page\n",
    "    html_code = driver.page_source\n",
    "\n",
    "    # parse the HTML code with BeautifulSoup\n",
    "    soup = BeautifulSoup(html_code, 'html.parser')\n",
    "\n",
    "    # find the <div> tag with class \"gs_a\"\n",
    "    div_tag = soup.find('div', class_='gs_a')\n",
    "    \n",
    "    # wait for search result page to load\n",
    "    time.sleep(2)\n",
    "    \n",
    "    if div_tag is not None:\n",
    "        text_content = div_tag.get_text()\n",
    "    \n",
    "        # split the text content by commas and strip any whitespace\n",
    "        author_names = [name.strip() for name in text_content.split(',')]\n",
    "\n",
    "        # split the second-to-last element of the list by the dash character\n",
    "        second_last_element_parts = author_names[-2].split('-')\n",
    "\n",
    "        # keep only the first part (i.e., the author name)\n",
    "        author_names[-2] = second_last_element_parts[0].strip()\n",
    "\n",
    "        author_names_cleaned = author_names[:-1]\n",
    "        # author_names_cleaned\n",
    "\n",
    "        # extract the author names and add \"-author:\" in front of each name\n",
    "        authors_list = ['-author:' + author for author in author_names_cleaned]\n",
    "\n",
    "        # join the author names into a single string with spaces in between\n",
    "        authors_str = ' '.join(authors_list)\n",
    "        print(authors_str)\n",
    "        row_num = article_titles.index(article_title) + 1  # get the row number of the current article title\n",
    "        ws.cell(row=row_num, column=3, value=authors_str)\n",
    "    \n",
    "    else:\n",
    "        print('Could not find author names')\n",
    "\n",
    "    # # extract all the text content within the <div> tag\n",
    "    # text_content = div_tag.get_text()\n",
    "\n",
    "\n",
    "    # check if there is a \"Cited by\" number\n",
    "    try:\n",
    "        cited_by = driver.find_element(By.PARTIAL_LINK_TEXT, 'Cited by')\n",
    "        cited_by.click()\n",
    "        \n",
    "        # wait for Captcha to load\n",
    "        time.sleep(20)\n",
    "    \n",
    "        # check \"Search within citing articles\" option\n",
    "        search_within = driver.find_element(By.ID, 'gs_scipsc')\n",
    "        search_within.click()\n",
    "\n",
    "        \n",
    "        # input the author names in search box\n",
    "        search_box = driver.find_element(By.NAME, 'q')\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(authors_str)\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "        \n",
    "        # find the number of search results and record it in the same row in column B\n",
    "        result_stats = driver.find_element(By.ID, 'gs_ab_md')\n",
    "        text_results = result_stats.text\n",
    "\n",
    "        try:\n",
    "            num_results = re.findall(r'\\d+', text_results)[0]\n",
    "            print(num_results)\n",
    "\n",
    "            row_num = article_titles.index(article_title) + 1  # get the row number of the current article title\n",
    "            ws.cell(row=row_num, column=2, value=num_results)\n",
    "        except IndexError:\n",
    "            print('No search results found')      \n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        # record 0 if there are no remaining\n",
    "        num_results = 0\n",
    "        print(num_results)\n",
    "        row_num = article_titles.index(article_title) + 1  # get the row number of the current article title\n",
    "        ws.cell(row=row_num, column=2, value=num_results)\n",
    "\n",
    "    # wait for main search page to load\n",
    "    time.sleep(1)\n",
    "\n",
    "    # navigate to Google Scholar\n",
    "    driver.get('https://scholar.google.com/schhp?hl=en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddbf83c2-ecb7-4c1c-9af0-a276a1dec08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the Excel sheet and close the webdriver\n",
    "wb.save('articles.xlsx')\n",
    "\n",
    "# close the browser window\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
